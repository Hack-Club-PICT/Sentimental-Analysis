{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1iDpatCxblupaCA_tnem60apEKXZIoyaN",
      "authorship_tag": "ABX9TyPAyd5lR9LmybWVv0rOQfsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akompalwad/Sentimental-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZLuQd4u0mRe"
      },
      "source": [
        "I have referred [this](https://arxiv.org/pdf/1809.08651.pdf) research paper for making the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI5_XJ8bEP82"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import re\n",
        "from nltk.stem.porter import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc9rK36DOLgE",
        "outputId": "06bc9568-cb72-428d-e502-283ba8d4f289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# this section is needed only if you get some error in nltk, it wouldnt hurt to\n",
        "# to run it though\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP0-OnxVEjub"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/datasets/train_twitter.csv',header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1fG0w1HE3yL",
        "outputId": "727d86ed-1073-4a95-90f6-4e19003467e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQroMh3PEquV"
      },
      "source": [
        "df = df[['label','tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hLZhdelba4D",
        "outputId": "4a23fb91-2117-42fd-d720-36180db77f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet\n",
              "0      0   @user when a father is dysfunctional and is s...\n",
              "1      0  @user @user thanks for #lyft credit i can't us...\n",
              "2      0                                bihday your majesty\n",
              "3      0  #model   i love u take with u all the time in ...\n",
              "4      0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3RVreWoFZwa",
        "outputId": "b1e150a5-bc65-4045-9817-03086c11cf2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#This tells us about the distribution of data\n",
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTHiJOpuGIeJ"
      },
      "source": [
        "**It can be seen that the data is highly imbalanced and number of positive tweets\n",
        "is too high than number of negative tweets\n",
        "For a good deep learning model it is really helpful when both the tweets are balanced.\n",
        "  It is highly important that the data is not skewed.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3K-UoKdFl1d"
      },
      "source": [
        "df_positive = df[df['label']==0]\n",
        "df_negative = df[df['label']==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4PWfAKxG_rS",
        "outputId": "a6ccccbf-3e62-455c-d789-195874358fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "df_train_positive = df_positive.sample(6000)\n",
        "df_train_negative = df_negative\n",
        "print(\"Train positive shape\",df_train_positive.shape)\n",
        "print(\"Train negative shape\",df_train_negative.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train positive shape (6000, 2)\n",
            "Train negative shape (2242, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4L3lkiUHDi9",
        "outputId": "4e39f271-5eaa-4003-8e98-c773eb4350da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "train_df = pd.concat([df_train_positive,df_train_negative])\n",
        "print(train_df.shape)\n",
        "print(\"\\n\")\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8242, 2)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19622</th>\n",
              "      <td>0</td>\n",
              "      <td>happy euro day ð¬</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1856</th>\n",
              "      <td>0</td>\n",
              "      <td>reading trumps speech transcripts. can't tell ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16392</th>\n",
              "      <td>0</td>\n",
              "      <td>meal before the premiere! mmm #lvff #nsc   #sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21020</th>\n",
              "      <td>0</td>\n",
              "      <td>uh oh, warranty on @user humanoid is apparentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26582</th>\n",
              "      <td>0</td>\n",
              "      <td>@user because lebron cried when he got trash t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                              tweet\n",
              "19622      0                              happy euro day ð¬  \n",
              "1856       0  reading trumps speech transcripts. can't tell ...\n",
              "16392      0  meal before the premiere! mmm #lvff #nsc   #sh...\n",
              "21020      0  uh oh, warranty on @user humanoid is apparentl...\n",
              "26582      0  @user because lebron cried when he got trash t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkdWW6swh_0u",
        "outputId": "ca2070ea-31b4-4ad4-f4c2-c212abf8a0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 8242 entries, 19622 to 31960\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   label    8242 non-null   int64 \n",
            " 1   tweet    8242 non-null   object\n",
            " 2   tweet_n  8242 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 257.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJguL6Fv7p41"
      },
      "source": [
        "def clear_texts(tweet,remove_pattern):\n",
        "  r = re.findall(remove_pattern,tweet)\n",
        "  for i in r:\n",
        "    tweet = re.sub(i,'',tweet)\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0P7bxf1hbKs"
      },
      "source": [
        "#WE remove the @user handles in the data as they dont give any relevant information\n",
        "train_df['tweet_n'] = np.vectorize(clear_texts)(train_df['tweet'],\"@[\\w]*\")\n",
        "#Now we remove the special characters and punctuations\n",
        "train_df['tweet_n'] = train_df['tweet_n'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
        "#we remove words with length less than 3 as most of them are just helping verbs and dont account for important data\n",
        "train_df['tweet_n'] = train_df['tweet_n'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "#make a list of tweets\n",
        "train_df['tweet_n'] = train_df['tweet_n'].apply(lambda x:x.split())\n",
        "#remove prefixes and suffixes from the words\n",
        "stemmer = PorterStemmer()\n",
        "train_df['tweet_n']= train_df['tweet_n'].apply(lambda x:[stemmer.stem(i) for i in x])\n",
        "#return the list from of tweets back to string\n",
        "train_df['tweet_n'] = train_df['tweet_n'].apply(lambda x:str(\" \".join(i for i in x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2oByLNrRS9l",
        "outputId": "3e906be5-b498-4957-9465-0ad49c2ac487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19622</th>\n",
              "      <td>0</td>\n",
              "      <td>happy euro day ð¬</td>\n",
              "      <td>happi euro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1856</th>\n",
              "      <td>0</td>\n",
              "      <td>reading trumps speech transcripts. can't tell ...</td>\n",
              "      <td>read trump speech transcript tell read year bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16392</th>\n",
              "      <td>0</td>\n",
              "      <td>meal before the premiere! mmm #lvff #nsc   #sh...</td>\n",
              "      <td>meal befor premier #lvff #nsc #shofilm #womeni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21020</th>\n",
              "      <td>0</td>\n",
              "      <td>uh oh, warranty on @user humanoid is apparentl...</td>\n",
              "      <td>warranti humanoid appar exactli year himself #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26582</th>\n",
              "      <td>0</td>\n",
              "      <td>@user because lebron cried when he got trash t...</td>\n",
              "      <td>becaus lebron cri when trash talk down then le...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                            tweet_n\n",
              "19622      0  ...                                         happi euro\n",
              "1856       0  ...  read trump speech transcript tell read year bo...\n",
              "16392      0  ...  meal befor premier #lvff #nsc #shofilm #womeni...\n",
              "21020      0  ...  warranti humanoid appar exactli year himself #...\n",
              "26582      0  ...  becaus lebron cri when trash talk down then le...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQNdacrKLJbh"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(train_df['tweet_n'],train_df['label'],test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-WM4bi_5WCm",
        "outputId": "47d7b470-7210-4962-f61c-0f83f1dd095e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "pipeline = Pipeline(\n",
        "    [\n",
        "     ('bow',CountVectorizer(ngram_range=(1,3))),\n",
        "     ('tfidf',TfidfTransformer(norm='l2')),\n",
        "     ('classifier',LogisticRegression(C=100,solver = 'liblinear')),\n",
        "    ]\n",
        ")\n",
        "pipeline.fit(x_train,y_train)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=100, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHwkkUDsKRLb"
      },
      "source": [
        "predictions = pipeline.predict(x_test)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlMpQ3evLvMq",
        "outputId": "0e685f31-1687-43a5-815d-50be9083ff5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "print(classification_report(predictions,y_test))\n",
        "print ('\\n')\n",
        "print(confusion_matrix(predictions,y_test))\n",
        "print(accuracy_score(predictions,y_test))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.91      0.93      1266\n",
            "           1       0.74      0.86      0.79       383\n",
            "\n",
            "    accuracy                           0.90      1649\n",
            "   macro avg       0.85      0.88      0.86      1649\n",
            "weighted avg       0.90      0.90      0.90      1649\n",
            "\n",
            "\n",
            "\n",
            "[[1150  116]\n",
            " [  55  328]]\n",
            "0.8963007883565798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGaiYn34t3-a"
      },
      "source": [
        "##The above model is used to make predictions about test dataset from [Analytics Vidhya](https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqQ0bYPkLwbr",
        "outputId": "222af40b-dcae-42cc-9886-b9323931e777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_df = pd.read_csv(r'/content/drive/My Drive/datasets/test_tweets.csv')\n",
        "test_df.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6mYvSWuMWYl"
      },
      "source": [
        "#WE remove the @user handles in the data as they dont give any relevant information\n",
        "test_df['tweet_n'] = np.vectorize(clear_texts)(test_df['tweet'],\"@[\\w]*\")\n",
        "#Now we remove the special characters and punctuations\n",
        "test_df['tweet_n'] = test_df['tweet_n'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
        "#we remove words with length less than 3 as most of them are just helping verbs and dont account for important data\n",
        "test_df['tweet_n'] = test_df['tweet_n'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "#make a list of tweets\n",
        "test_df['tweet_n'] = test_df['tweet_n'].apply(lambda x:x.split())\n",
        "#remove prefixes and suffixes from the words\n",
        "stemmer = PorterStemmer()\n",
        "test_df['tweet_n']= test_df['tweet_n'].apply(lambda x:[stemmer.stem(i) for i in x])\n",
        "#return the list from of tweets back to string\n",
        "test_df['tweet_n'] = test_df['tweet_n'].apply(lambda x:str(\" \".join(i for i in x)))"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDRgtJkjNWIt",
        "outputId": "a6d33dc6-2dee-45f1-f540-762de9b6ee66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolif #aislif #requir #passion #dedic #wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>#white #supremacist want everyon #bird #movi here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe way heal your #acn #altwaystoh #healthi #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>curs child book reserv alreadi where when #har...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>#bihday amaz hilari #nephew ahmir uncl dave lo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                            tweet_n\n",
              "0  31963  ...  #studiolif #aislif #requir #passion #dedic #wi...\n",
              "1  31964  ...  #white #supremacist want everyon #bird #movi here\n",
              "2  31965  ...  safe way heal your #acn #altwaystoh #healthi #...\n",
              "3  31966  ...  curs child book reserv alreadi where when #har...\n",
              "4  31967  ...  #bihday amaz hilari #nephew ahmir uncl dave lo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0BUFsdANYv8"
      },
      "source": [
        "result = pipeline.predict(test_df['tweet_n'])\n",
        "result = pd.DataFrame(result)\n",
        "result.to_csv('result16.csv')"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIUv1CSMtiRi"
      },
      "source": [
        "##The code below this is for the api that we will be using for getting input in form of string and using our model on it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QrJ5xFITCbY"
      },
      "source": [
        "test_string = \"Thank you @rseroter for the first ever, 10-tweet, VM to container App migration tutorial. It's that easy! (awesome job  @googlecloudteam) \""
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1OZ4x8rN39y"
      },
      "source": [
        "import pickle\n",
        "pickle_file = 'sk_model.pkl'\n",
        "with open(pickle_file,'wb') as file:\n",
        "  pickle.dump(pipeline,file)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIU6Dak4S6Jd",
        "outputId": "f86fc834-880a-4763-bb29-2941965ccc45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "with open(pickle_file, 'rb') as file:  \n",
        "    Pickled_LR_Model = pickle.load(file)\n",
        "\n",
        "Pickled_LR_Model"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=100, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Ux_sxbYRHz"
      },
      "source": [
        "def text_preprocessing(string):\n",
        "  def clear_texts(tweet,remove_pattern):\n",
        "    r = re.findall(remove_pattern,tweet)\n",
        "    for i in r:\n",
        "      tweet = re.sub(i,'',tweet)\n",
        "    return tweet\n",
        "  #WE remove the @user handles in the data as they dont give any relevant information\n",
        "  string = np.vectorize(clear_texts)(np.array(string),\"@[\\w]*\")\n",
        "  #Now we remove the special characters and punctuations\n",
        "  string= str(string).replace(\"[^a-zA-Z#]\",\" \")\n",
        "  #make a list of tweets\n",
        "  string = string.split()\n",
        "  #we remove words with length less than 3 as most of them are just helping verbs and dont account for important data\n",
        "  string = ' '.join([w for w in string if len(w)>3])\n",
        "  #remove prefixes and suffixes from the words\n",
        "  stemmer = PorterStemmer()\n",
        "  string= [stemmer.stem(i) for i in string.split()]\n",
        "  #return the list from of tweets back to string\n",
        "  string = \" \".join(i for i in string)\n",
        "  return string"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkZdTlPcYxHi"
      },
      "source": [
        "res = text_preprocessing(test_string)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9E0UJ2IbpwU"
      },
      "source": [
        "res = [res]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhs25DkxkjiG",
        "outputId": "4e632888-d227-4692-db76-ab90a780a5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Pickled_LR_Model.predict(res)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtGaxmiRl90x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
